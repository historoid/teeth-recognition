{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のファイル名から正解ラベルを作る\n",
    "# まずはモジュールのインポート\n",
    "import re\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class makeDataSet:\n",
    "    # インスタンス変数の定義とファイル名の取得\n",
    "    def __init__(self, img_dir, img_size):\n",
    "        self.img_size = img_size\n",
    "        self.img_dir_obj = pathlib.Path(img_dir)\n",
    "        self.img_all_list = list(self.img_dir_obj.glob('*.png'))\n",
    "        self.img_all_list = random.sample(self.img_all_list, len(self.img_all_list))\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.dent = [\n",
    "            11, 12, 13, 14, 15, 16, 17, 18,\n",
    "            21, 22, 23, 24, 25, 26, 27, 28,\n",
    "            31, 32, 33, 34, 35, 36, 37, 38,\n",
    "            41, 42, 43, 44, 45, 46, 47, 48]\n",
    "\n",
    "\n",
    "    # 画像をnp配列に変換\n",
    "    def imageToArray(self, img_list):\n",
    "        for fn in img_list:\n",
    "            img_array = img_to_array(load_img(fn))\n",
    "            self.x.append(img_array)\n",
    "        self.x = np.asarray(self.x, dtype=np.float32)\n",
    "        self.x /= 255.0\n",
    "        return self.x\n",
    "\n",
    "\n",
    "    # ファイル名をk-hotエンコーディング\n",
    "    def k_hot_encode(self, img_list):\n",
    "        for fn in img_list:\n",
    "            k_hot_teeth = [0]*32\n",
    "            fn = re.sub('.*-', '', str(fn))\n",
    "            fn = fn.strip('.png')\n",
    "            fn = fn.split(',')\n",
    "            fn = [int(k) for k in fn]\n",
    "            for tooth in fn:\n",
    "                if tooth in self.dent:\n",
    "                    k_hot_teeth[self.dent.index(tooth)] = 1\n",
    "            self.y.append(k_hot_teeth)\n",
    "        self.y = np.asarray(self.y, dtype=np.float32)\n",
    "        return self.y\n",
    "\n",
    "\n",
    "    # 使用する画像の枚数を指定\n",
    "    def pickupImages(self, pick_num):\n",
    "        self.pickup_img = self.img_all_list[:pick_num]\n",
    "        return self.pickup_img\n",
    "    \n",
    "    \n",
    "    # 画像サイズを変更したいとき\n",
    "    def adjustedImgArray(self, img_list):\n",
    "        for fn in img_list:\n",
    "            ad_img = keras.preprocessing.image.load_img(fn, target_size=(self.img_size, self.img_size))\n",
    "            ad_img_array = img_to_array(ad_img)\n",
    "            self.x.append(ad_img_array)\n",
    "        self.x = np.asarray(self.x, dtype=np.float32)\n",
    "        self.x /= 255.0    \n",
    "        return self.x\n",
    "\n",
    "    \n",
    "    #  訓練データと確認データを切り分ける\n",
    "    def devideData(self, img_array, img_label, test_size):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(img_array, img_label, test_size=test_size)\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/Users/seino/Documents/research/DeepLearning/playground/img'\n",
    "ds = makeDataSet(img_dir, 32)\n",
    "'''\n",
    "img_list = ds.pickupImages(1000)\n",
    "img_array = ds.adjustedImgArray(img_list)\n",
    "img_label = ds.k_hot_encode(img_list)\n",
    "'''\n",
    "img_list = ds.img_all_list\n",
    "img_array = ds.adjustedImgArray(img_list)\n",
    "img_label = ds.k_hot_encode(img_list)\n",
    "\n",
    "test_size = 0.2\n",
    "x_train, x_test, y_train, y_test = ds.devideData(img_array, img_label, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化して確認\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習に必要なモジュールをインポートする\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のサイズ定義\n",
    "img_size = ds.img_size\n",
    "height, width, channels = img_size, img_size, 3\n",
    "class_num = len(ds.dent) # 歯種がクラスになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの構築\n",
    "model = models.Sequential()\n",
    "model.add(layers.SeparableConv2D(img_size, 3, activation='relu', input_shape=(height, width, channels)))\n",
    "model.add(layers.SeparableConv2D(img_size*2, 3, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(img_size*2, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(img_size*4, 3, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(img_size*4, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(img_size*8, 3, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(img_size*4, activation='relu'))\n",
    "model.add(layers.Dense(img_size*2, activation='relu'))\n",
    "model.add(layers.Dense(class_num, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='callbacks.h5',\n",
    "        monitor='val_acc',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='./log',\n",
    "        histogram_freq=1,\n",
    "        batch_size=32,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        embeddings_freq=1,\n",
    "        embeddings_layer_names=None,\n",
    "        embeddings_metadata=None\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=50,\n",
    "    epochs=20, validation_data = (x_test, y_test), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('heatmap.h5')\n",
    "\n",
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_acc, linestyle='--', color='b')\n",
    "plt.plot(val_acc, linestyle='-', color='#e46409')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss, linestyle='--', color='b')\n",
    "plt.plot(val_loss, linestyle='-', color='#e46409')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 活性化マップを可視化する。\n",
    "layer_outputs = [layer.output for layer in model.layers[:4]]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(x_train)\n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "plt.matshow(first_layer_activation[0, :, :, 3], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各レイヤーの名前を抽出\n",
    "layer_names = []\n",
    "for layer in model.layers[:4]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "# 一行に表示する画像の数\n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # レイヤーの特徴マップ数を取得\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    # 特徴マップのサイズを取得\n",
    "    size = layer_activation.shape[1]\n",
    "    # 画像の行数を計算し画像を並べる0行列を生成\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "            # 特徴マップを標準化\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            # 平均128、標準偏差64に変換\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            # 0-255に符号なし8ビット整数化\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            # 所定の位置にイメージを埋め込む\n",
    "            display_grid[col * size : (col + 1) * size, row * size: (row +1) * size ] = channel_image\n",
    "    # 画像の表示\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下、学習モデルを用いて、ヒートマップを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデルを用いて、ヒートマップと元の画像を重ねて表示する\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# ターゲット画像へのローカルパス\n",
    "img_path = '/Users/seino/Documents/research/DeepLearning/playground/img/RU2512ULG-11,12,13,14,16,17,23,24,26,32,33,34,36,41,43,45,47.png'\n",
    "# 読み込み\n",
    "img = image.load_img(img_path, target_size=(ds.img_size, ds.img_size))\n",
    "# 画像を配列に変換\n",
    "img_na = image.img_to_array(img)\n",
    "# バッチに変換するために次元を追加\n",
    "img_na = np.expand_dims(img_na, axis=0)\n",
    "# 前処理。チャネルごとに色を正規化\n",
    "img_na = preprocess_input(img_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル画像に対する予測\n",
    "preds = model.predict_classes(img_na)\n",
    "pred_class = preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測ベクトルはpred_class\n",
    "dent_output = model.output[:, pred_class]\n",
    "# 畳み込み層を取得\n",
    "last_conv_layer = model.get_layer('separable_conv2d_2')\n",
    "# 特徴マップの勾配を取得\n",
    "grads = keras.backend.gradients(dent_output, last_conv_layer.output)[0]\n",
    "# 形状が(32,)のベクトル\n",
    "# 各ラベルは特定の特徴マップチャネルの勾配の平均強度\n",
    "pooled_grads = keras.backend.mean(grads, axis=(0, 1, 2))\n",
    "# サンプル画像に基づいて、平均強度と特徴出力マップにアクセス\n",
    "iterate = keras.backend.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "# 上記をnumpy配列に\n",
    "pooled_grads_value, conv_layer_output_value = iterate([img_na])\n",
    "# このクラスに対するチャネルの重要度を特徴マップに重み付け\n",
    "for i in range(32):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "# 最終的な特徴マップのチャネルごとの平均値がクラスの活性化ヒートマップになる\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "# ヒートマップの後処理\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2でスーパーインポーズ\n",
    "import cv2\n",
    "# 元画像の読み込み\n",
    "img_cv = cv2.imread(img_path)\n",
    "# ヒートマップのサイズと元画像のサイズを合わせる\n",
    "heatmap = cv2.resize(heatmap, (img_cv.shape[1], img_cv.shape[0]))\n",
    "# ヒートマップをRGBに変換\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "cv2.imwrite('/Users/seino/Downloads/map.png', heatmap)\n",
    "# ヒートマップを元画像に適応\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "# 透明度40%でスーパーインポーズ\n",
    "superimposed_heatimg = heatmap * 0.5 + img_cv\n",
    "cv2.imwrite('/Users/seino/Downloads/heat.png', superimposed_heatimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.2.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
